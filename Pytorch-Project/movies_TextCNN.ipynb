{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movies_TextCNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAzX4ge_NAQz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('./movies.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIchBpReOvjj",
        "outputId": "1a7a2231-65a2-495e-8e55-cf0e946c9acf"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.6 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaoDZI2XNxmP"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "df['token_final'] = df.overview.apply(okt.nouns)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "nMiWIykBNxqs",
        "outputId": "d7ad1f70-6afd-4c14-b1dd-01447c204f34"
      },
      "source": [
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>overview</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>label</th>\n",
              "      <th>token_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>용감한 자가 신부를 데려가리</td>\n",
              "      <td>영국에서 유학중인 라즈 샤룩 칸 와 인도 처녀 심란 까졸   심란은 부모님이 정해주...</td>\n",
              "      <td>8.7</td>\n",
              "      <td>3215</td>\n",
              "      <td>True</td>\n",
              "      <td>[영국, 유학, 라즈, 샤룩, 칸, 인도, 처녀, 심란, 까졸, 심란, 부모님, 정...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>쇼생크 탈출</td>\n",
              "      <td>촉망받는 은행 간부 앤디 듀프레인은 아내와 그녀의 정부를 살해했다는 누명을 쓴다  ...</td>\n",
              "      <td>8.7</td>\n",
              "      <td>20082</td>\n",
              "      <td>True</td>\n",
              "      <td>[촉망, 은행, 간부, 앤디, 듀, 프레, 아내, 그녀, 정부, 살해, 누명, 주변...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>대부</td>\n",
              "      <td>시실리에서 이민온 뒤  정치권까지 영향력을 미치는 거물로 자리잡은 돈 꼴레오네는 갖...</td>\n",
              "      <td>8.7</td>\n",
              "      <td>15045</td>\n",
              "      <td>True</td>\n",
              "      <td>[시실리, 이민, 온, 뒤, 정치권, 영향력, 거물, 자리, 돈, 꼴레오네, 갖가지...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>쉰들러 리스트</td>\n",
              "      <td>2차 세계대전 당시 독일군이 점령한 폴란드  시류에 맞춰 자신의 성공을 추구하는 기...</td>\n",
              "      <td>8.6</td>\n",
              "      <td>12007</td>\n",
              "      <td>True</td>\n",
              "      <td>[차, 세계대전, 당시, 독일군, 점령, 폴란드, 시류, 자신, 성공, 추구, 기회...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>에반게리온 3.0+1.01</td>\n",
              "      <td>에반게리온 신극장판의 제4탄이자 완결편  미사토와 반네르프 조직 빌레는 코어와 닮은...</td>\n",
              "      <td>8.6</td>\n",
              "      <td>366</td>\n",
              "      <td>True</td>\n",
              "      <td>[에반게리온, 극장판, 제, 완결, 편, 미사, 토, 르프, 조직, 빌레, 코어, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        token_final\n",
              "0           0  ...  [영국, 유학, 라즈, 샤룩, 칸, 인도, 처녀, 심란, 까졸, 심란, 부모님, 정...\n",
              "1           1  ...  [촉망, 은행, 간부, 앤디, 듀, 프레, 아내, 그녀, 정부, 살해, 누명, 주변...\n",
              "2           2  ...  [시실리, 이민, 온, 뒤, 정치권, 영향력, 거물, 자리, 돈, 꼴레오네, 갖가지...\n",
              "3           3  ...  [차, 세계대전, 당시, 독일군, 점령, 폴란드, 시류, 자신, 성공, 추구, 기회...\n",
              "4           4  ...  [에반게리온, 극장판, 제, 완결, 편, 미사, 토, 르프, 조직, 빌레, 코어, ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sHddpic7NxtA",
        "outputId": "991f1874-8fb6-43ad-f881-29bc8ee8f279"
      },
      "source": [
        "df_drop = df[['token_final', 'label']]\n",
        "df_drop.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_final</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[영국, 유학, 라즈, 샤룩, 칸, 인도, 처녀, 심란, 까졸, 심란, 부모님, 정...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[촉망, 은행, 간부, 앤디, 듀, 프레, 아내, 그녀, 정부, 살해, 누명, 주변...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[시실리, 이민, 온, 뒤, 정치권, 영향력, 거물, 자리, 돈, 꼴레오네, 갖가지...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[차, 세계대전, 당시, 독일군, 점령, 폴란드, 시류, 자신, 성공, 추구, 기회...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[에반게리온, 극장판, 제, 완결, 편, 미사, 토, 르프, 조직, 빌레, 코어, ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         token_final  label\n",
              "0  [영국, 유학, 라즈, 샤룩, 칸, 인도, 처녀, 심란, 까졸, 심란, 부모님, 정...   True\n",
              "1  [촉망, 은행, 간부, 앤디, 듀, 프레, 아내, 그녀, 정부, 살해, 누명, 주변...   True\n",
              "2  [시실리, 이민, 온, 뒤, 정치권, 영향력, 거물, 자리, 돈, 꼴레오네, 갖가지...   True\n",
              "3  [차, 세계대전, 당시, 독일군, 점령, 폴란드, 시류, 자신, 성공, 추구, 기회...   True\n",
              "4  [에반게리온, 극장판, 제, 완결, 편, 미사, 토, 르프, 조직, 빌레, 코어, ...   True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLxHCGnWNxvR"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TShFQGmNxxe",
        "outputId": "eba710b4-c861-451b-a71b-76f3ce6422cf"
      },
      "source": [
        "embedding_model = Word2Vec(\n",
        "    df_drop['token_final'],\n",
        "    sg = 1,\n",
        "    size = 100,\n",
        "    window = 2,\n",
        "    min_count = 1,\n",
        "    workers = 4\n",
        "    )\n",
        "print(embedding_model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=14182, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMXxEAIaNxzj",
        "outputId": "10edb872-04c1-4001-cabc-a1a462f2805b"
      },
      "source": [
        "model_result = embedding_model.wv.most_similar('은행')\n",
        "print(model_result)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('무기', 0.9997416138648987), ('환상', 0.9997378587722778), ('린', 0.9997240304946899), ('달러', 0.9997202157974243), ('전체', 0.9997150301933289), ('도중', 0.9997121691703796), ('칼', 0.9997060298919678), ('마련', 0.9997059106826782), ('노', 0.999700665473938), ('컴퓨터', 0.999699592590332)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kgPmiajNx12"
      },
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3nIUNdLQ93b",
        "outputId": "8ae03579-2021-4e0e-80b9-83b93821ca5f"
      },
      "source": [
        "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v')\n",
        "\n",
        "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v')\n",
        "\n",
        "model_result = loaded_model.most_similar('은행')\n",
        "print(model_result)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('무기', 0.9997416138648987), ('환상', 0.9997378587722778), ('린', 0.9997240304946899), ('달러', 0.9997202157974243), ('전체', 0.9997150301933289), ('도중', 0.9997121691703796), ('칼', 0.9997060298919678), ('마련', 0.9997059106826782), ('노', 0.999700665473938), ('컴퓨터', 0.999699592590332)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vmMMyegQ952"
      },
      "source": [
        "from numpy.random import RandomState"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR13WZMMQ98Y"
      },
      "source": [
        "rng = RandomState()\n",
        "\n",
        "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
        "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
        "\n",
        "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
        "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcnpIi-2Q9-o"
      },
      "source": [
        "import torchtext\n",
        "from torchtext.legacy.data import Field\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
        "    text = text.split(', ')\n",
        "    return text\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer)\n",
        "LABEL = Field(sequential = False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMI1hZy8Q-A_"
      },
      "source": [
        "from torchtext.legacy.data import TabularDataset"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx6sdaNMQ-DR",
        "outputId": "b689b02b-e564-4a2f-fc2c-d35b024758ee"
      },
      "source": [
        "import re\n",
        "\n",
        "train, validation = TabularDataset.splits(\n",
        "    path = 'data/',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = [('text', TEXT), ('label', LABEL)],\n",
        "    skip_header = True\n",
        ")\n",
        "\n",
        "print('Train:', train[0].text, train[0].label)\n",
        "print('Validation:', validation[0].text, validation[0].label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: ['친구', '귀지', '못', '학교', '적응', '소년', '짐', '스타크', '술', '경찰서', '짐', '경찰서', '밤길', '온', '디', '강아지', '총', '온', '소년', '플라토', '청소년', '경찰', '레이', '짐', '부모', '대한', '불만', '것', '알', '어려움', '자기', '말', '며칠', '후', '새', '학교', '등교', '짐', '디', '버즈', '일당', '패거리', '버즈', '짐', '만', '음', '경주', '하자', '도전'] True\n",
            "Validation: ['시실리', '이민', '온', '뒤', '정치권', '영향력', '거물', '자리', '돈', '꼴레오네', '갖가지', '고민', '호소', '사람', '문제', '해결', '대부', '한편', '솔로', '소라', '인물', '꼴레오네', '라이벌', '탓', '리아', '패밀리', '마약', '사업', '제안', '돈', '꼴레오네', '마약', '사업', '참여', '하자', '돈', '꼴레오네', '저격', '그', '중상', '사경', '그', '뒤', '돈', '꼴레오네', '아들', '소니', '조직', '총', '동원', '다른', '패밀리', '피', '전쟁', '시작', '가족', '사업', '대학', '진학', '뒤', '인텔리', '막내', '아들', '마이클', '아버지', '총격', '당한', '뒤', '아버지', '구', '위해', '위험천만', '협상', '자리'] True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsCfjSPST1Ep",
        "outputId": "4e44d0df-a7e6-4115-903d-7601a81f9121"
      },
      "source": [
        "t = f = 0\n",
        "i = 0\n",
        "while True:\n",
        "    try:\n",
        "        if train[i].label == 'True':\n",
        "            t += 1\n",
        "        else:\n",
        "            f += 1\n",
        "        i += 1\n",
        "    except:\n",
        "        break\n",
        "\n",
        "i = 0\n",
        "while True:\n",
        "    try:\n",
        "        if validation[i].label == 'True':\n",
        "            t += 1\n",
        "        else:\n",
        "            f += 1\n",
        "        i += 1\n",
        "    except:\n",
        "        break\n",
        "\n",
        "print(t, f)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "909 873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wByUhNqVQ-FU"
      },
      "source": [
        "import torch\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.legacy.data import BucketIterator"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmn8iG5wQ-Hl",
        "outputId": "372a0185-7fa7-4f02-855a-00b423600bd3"
      },
      "source": [
        "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
        "\n",
        "TEXT.build_vocab(train, vectors=vectors, min_freq=1, max_size=None)\n",
        "\n",
        "LABEL.build_vocab(train)\n",
        "\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train, validation),\n",
        "    batch_size = 8,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {}'.format(TEXT.vocab.vectors.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/14182 [00:00<?, ?it/s]Skipping token b'14182' with 1-dimensional vector [b'100']; likely a header\n",
            "100%|██████████| 14182/14182 [00:00<00:00, 18506.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 벡터의 개수와 차원 : torch.Size([12789, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQmt310TMfl"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-d7ayCFRaim"
      },
      "source": [
        "## TextCNN 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RINn3h5Q-Jy"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        emb_x = self.embed(x)\n",
        "        emb_x = emb_x.unsqueeze(1)\n",
        "\n",
        "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]\n",
        "\n",
        "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]\n",
        "\n",
        "        fc_x = torch.cat(pool_x, dim=1)\n",
        "        fc_x = fc_x.squeeze(-1)\n",
        "        fc_x = self.dropout(fc_x)\n",
        "\n",
        "        logit = self.fc(fc_x)\n",
        "\n",
        "        return logit"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK358oQaQ-MF"
      },
      "source": [
        "def train(model, device, train_itr, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    corrects, train_loss = 0.0, 0\n",
        "\n",
        "    for batch in train_itr:\n",
        "\n",
        "        text, target = batch.text, batch.label\n",
        "        text = torch.transpose(text, 0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logit = model(text)\n",
        "\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        result = torch.max(logit, 1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "\n",
        "    train_loss /= len(train_itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
        "\n",
        "    return train_loss, accuracy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_vKq0jHQ-OX"
      },
      "source": [
        "def evaluate(model, device, itr):\n",
        "\n",
        "    model.eval()\n",
        "    corrects, test_loss = 0.0, 0\n",
        "\n",
        "    for batch in itr:\n",
        "\n",
        "        text, target = batch.text, batch.label\n",
        "        text = torch.transpose(text, 0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "\n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        result = torch.max(logit, 1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "\n",
        "    test_loss /= len(itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
        "\n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaO2CJvwQ-Qd",
        "outputId": "4133a293-45c6-4515-9071-dd4afc3e2bb8"
      },
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
        "print(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextCNN(\n",
            "  (embed): Embedding(12789, 100)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwhcGlE7Q-Sr",
        "outputId": "cb406dfd-8656-452e-e450-7886be2de0dd"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = -1\n",
        "\n",
        "for epoch in range(1, 7+1):\n",
        "    tr_loss, tr_acc = train(model, device, train_iter, optimizer)\n",
        "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
        "\n",
        "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
        "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
        "\n",
        "    if val_acc > best_test_acc:\n",
        "        best_test_acc = val_acc\n",
        "        print('model saves at {} accuracy'.format(best_test_acc))\n",
        "        torch.save(model.state_dict(), 'TextCNN_Best_Validation')\n",
        "\n",
        "    print('-------------------------------------------------------------------------------')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \t Loss: 0.08735288945020164 \t Accuracy: 50.63113784790039%\n",
            "Valid Epoch: 1 \t Loss: 0.08770369997854983 \t Accuracy: 47.191009521484375%\n",
            "model saves at 47.191009521484375 accuracy\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 2 \t Loss: 0.08546049272194818 \t Accuracy: 57.433380126953125%\n",
            "Valid Epoch: 2 \t Loss: 0.08655850103731906 \t Accuracy: 54.7752799987793%\n",
            "model saves at 54.7752799987793 accuracy\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 3 \t Loss: 0.06866212797365549 \t Accuracy: 80.01402282714844%\n",
            "Valid Epoch: 3 \t Loss: 0.08433327530876975 \t Accuracy: 57.30337142944336%\n",
            "model saves at 57.30337142944336 accuracy\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 4 \t Loss: 0.026830313647581268 \t Accuracy: 94.60028076171875%\n",
            "Valid Epoch: 4 \t Loss: 0.0925208196211397 \t Accuracy: 56.741573333740234%\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 5 \t Loss: 0.00979273351396566 \t Accuracy: 98.1065902709961%\n",
            "Valid Epoch: 5 \t Loss: 0.09909492814808749 \t Accuracy: 58.70786666870117%\n",
            "model saves at 58.70786666870117 accuracy\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 6 \t Loss: 0.004369889556784261 \t Accuracy: 99.50911712646484%\n",
            "Valid Epoch: 6 \t Loss: 0.10906394211094031 \t Accuracy: 61.51685333251953%\n",
            "model saves at 61.51685333251953 accuracy\n",
            "-------------------------------------------------------------------------------\n",
            "Train Epoch: 7 \t Loss: 0.0041194191551889746 \t Accuracy: 99.4389877319336%\n",
            "Valid Epoch: 7 \t Loss: 0.11630422697308358 \t Accuracy: 58.988765716552734%\n",
            "-------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}